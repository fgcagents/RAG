# examples/module2_example.py
"""
Exemple complet d'Ãºs del MÃ²dul 2: Document Processing & Indexing
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from modules.ingestion.docstore import DocumentStoreManager
from modules.processing import (
    ChunkingStrategy,
    EmbeddingGenerator,
    VectorStoreManager,
    IndexBuilder,
    MetadataIndex,
    hybrid_search,
    build_complete_pipeline
)
from llama_index.core import Document
import logging

# Configurar logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def example_1_chunking():
    """
    Exemple 1: Chunking amb diferents estratÃ¨gies
    """
    print("\n" + "="*70)
    print("EXEMPLE 1: CHUNKING STRATEGIES")
    print("="*70)
    
    # Document de prova
    text = """
    # PolÃ­tica de Vacances
    
    Els empleats tenen dret a 30 dies de vacances a l'any. Les vacances s'han de
    solÂ·licitar amb un mÃ­nim de 15 dies d'antelaciÃ³. Durant els mesos de juliol i
    agost, es requereix una antelaciÃ³ de 30 dies.
    
    ## Procediment
    
    1. SolÂ·licitar les vacances al sistema
    2. Esperar aprovaciÃ³ del supervisor
    3. Confirmar les dates
    
    Les vacances no gaudides es poden acumular fins a un mÃ xim de 5 dies per al
    segÃ¼ent any fiscal.
    """
    
    doc = Document(
        text=text,
        metadata={'filename': 'vacances.md', 'department': 'HR'}
    )
    
    strategies = ['sentence', 'fixed_size', 'recursive']
    
    for strategy in strategies:
        print(f"\nğŸ”§ EstratÃ¨gia: {strategy}")
        
        chunker = ChunkingStrategy(
            strategy=strategy,
            chunk_size=200,
            chunk_overlap=20
        )
        
        nodes = chunker.chunk_documents([doc], show_progress=False)
        
        print(f"  âœ“ Chunks generats: {len(nodes)}")
        
        stats = chunker.get_statistics(nodes)
        print(f"  âœ“ Longitud mitjana: {stats['avg_chunk_length']:.0f} chars")
        print(f"  âœ“ Min/Max: {stats['min_chunk_length']}/{stats['max_chunk_length']}")
        
        # Mostrar primer chunk
        if nodes:
            print(f"  ğŸ“„ Primer chunk:")
            print(f"     {nodes[0].get_content()[:100]}...")


def example_2_embeddings():
    """
    Exemple 2: GeneraciÃ³ d'embeddings
    """
    print("\n" + "="*70)
    print("EXEMPLE 2: EMBEDDING GENERATION")
    print("="*70)
    
    # Crear alguns nodes
    text_samples = [
        "PolÃ­tica de vacances: 30 dies a l'any",
        "Procediment de solÂ·licitud de vacances",
        "AcumulaciÃ³ de dies no gaudits"
    ]
    
    nodes = [
        Document(text=text, metadata={'id': i})
        for i, text in enumerate(text_samples)
    ]
    
    # Chunking simple
    chunker = ChunkingStrategy(strategy='sentence', chunk_size=100)
    nodes = chunker.chunk_documents(nodes, show_progress=False)
    
    print(f"\nğŸ“Š Nodes preparats: {len(nodes)}")
    
    # Provar amb model local (no requereix API key)
    print("\nğŸ¤– Model: BGE-M3 (multilingÃ¼e, local)")
    
    try:
        embedder = EmbeddingGenerator(
            model_name='bge-m3',
            batch_size=10
        )
        
        print(f"  âœ“ Model info:")
        info = embedder.get_model_info()
        print(f"    - Dimensions: {info['dimensions']}")
        print(f"    - MultilingÃ¼e: {info['multilingual']}")
        print(f"    - Max tokens: {info['max_tokens']}")
        
        # Generar embeddings
        print(f"\n  ğŸ”„ Generant embeddings...")
        nodes = embedder.embed_nodes(nodes, show_progress=False)
        
        print(f"  âœ“ Embeddings generats!")
        print(f"  âœ“ Dimensions: {len(nodes[0].embedding)}")
        print(f"  âœ“ Primer embedding (preview): {nodes[0].embedding[:5]}...")
        
    except Exception as e:
        print(f"  âš ï¸  Error amb BGE-M3: {e}")
        print(f"  ğŸ’¡ InstalÂ·la: pip install sentence-transformers torch")


def example_3_vector_store():
    """
    Exemple 3: Vector Store amb ChromaDB (fÃ cil)
    """
    print("\n" + "="*70)
    print("EXEMPLE 3: VECTOR STORE (ChromaDB)")
    print("="*70)
    
    try:
        # Crear vector store
        print("\nğŸ’¾ Inicialitzant ChromaDB...")
        
        vector_store = VectorStoreManager(
            backend='chroma',
            collection_name='test_collection',
            persist_path='data/vector_stores/test',
            dimension=384  # Per bge-small o similar
        )
        
        print(f"  âœ“ Vector store creat")
        print(f"  âœ“ Backend: {vector_store.backend}")
        print(f"  âœ“ ColÂ·lecciÃ³: {vector_store.collection_name}")
        
        # Crear nodes amb embeddings dummy
        from llama_index.core.schema import TextNode
        import random
        
        nodes = []
        for i in range(5):
            node = TextNode(
                text=f"Document {i} sobre polÃ­tica de vacances",
                metadata={'doc_id': i, 'department': 'HR'}
            )
            # Embedding dummy (random)
            node.embedding = [random.random() for _ in range(384)]
            nodes.append(node)
        
        print(f"\n  ğŸ“¥ Afegint {len(nodes)} nodes...")
        results = vector_store.add_nodes(nodes, show_progress=False)
        
        print(f"  âœ“ Nodes afegits: {results['added']}")
        
        # Query
        print(f"\n  ğŸ” Provant cerca vectorial...")
        query_embedding = [random.random() for _ in range(384)]
        
        results = vector_store.query(
            query_embedding=query_embedding,
            top_k=3
        )
        
        print(f"  âœ“ Resultats trobats: {len(results.nodes)}")
        
        for i, node in enumerate(results.nodes):
            print(f"    {i+1}. {node.text[:50]}... (score: {results.similarities[i]:.3f})")
        
        # EstadÃ­stiques
        print(f"\n  ğŸ“Š EstadÃ­stiques:")
        stats = vector_store.get_statistics()
        for key, value in stats.items():
            print(f"    - {key}: {value}")
        
    except ImportError:
        print("  âš ï¸  ChromaDB no instalÂ·lat")
        print("  ğŸ’¡ InstalÂ·la: pip install chromadb")
    except Exception as e:
        print(f"  âŒ Error: {e}")


def example_4_metadata_index():
    """
    Exemple 4: Metadata Index
    """
    print("\n" + "="*70)
    print("EXEMPLE 4: METADATA INDEX")
    print("="*70)
    
    from llama_index.core.schema import TextNode
    
    # Crear nodes amb metadata
    nodes = [
        TextNode(
            text="Document IT sobre seguretat",
            metadata={
                'department': 'IT',
                'category': 'security',
                'language': 'ca',
                'year': 2024
            }
        ),
        TextNode(
            text="Document Legal sobre contractes",
            metadata={
                'department': 'Legal',
                'category': 'contracts',
                'language': 'ca',
                'year': 2024
            }
        ),
        TextNode(
            text="Document IT sobre xarxes",
            metadata={
                'department': 'IT',
                'category': 'network',
                'language': 'es',
                'year': 2023
            }
        )
    ]
    
    print(f"\nğŸ“‹ Indexant metadata de {len(nodes)} nodes...")
    
    # Crear metadata index
    metadata_index = MetadataIndex(
        persist_path='data/indexes/metadata/test'
    )
    
    metadata_index.index_nodes(nodes)
    
    print(f"  âœ“ Nodes indexats: {len(nodes)}")
    
    # Cerca 1: Departament IT
    print(f"\n  ğŸ” Cerca: department='IT'")
    results = metadata_index.search({'department': 'IT'})
    print(f"  âœ“ Resultats: {len(results)} nodes")
    
    # Cerca 2: IT en catalÃ 
    print(f"\n  ğŸ” Cerca: department='IT' AND language='ca'")
    results = metadata_index.search(
        {'department': 'IT', 'language': 'ca'},
        match_all=True
    )
    print(f"  âœ“ Resultats: {len(results)} nodes")
    
    # Valors Ãºnics
    print(f"\n  ğŸ“Š Valors Ãºnics:")
    departments = metadata_index.get_unique_values('department')
    print(f"    - Departaments: {departments}")
    
    # Value counts
    counts = metadata_index.get_value_counts('department')
    print(f"    - Conteos: {counts}")
    
    # EstadÃ­stiques
    print(f"\n  ğŸ“Š EstadÃ­stiques:")
    stats = metadata_index.get_statistics()
    print(f"    - Total nodes: {stats['total_nodes']}")
    print(f"    - Camps indexats: {stats['indexed_fields']}")


def example_5_complete_pipeline():
    """
    Exemple 5: Pipeline complet
    """
    print("\n" + "="*70)
    print("EXEMPLE 5: PIPELINE COMPLET")
    print("="*70)
    
    # Carregar documents del DocStore (MÃ²dul 1)
    print("\nğŸ“‚ Carregant documents del DocStore...")
    
    try:
        docstore = DocumentStoreManager(
            backend='simple',
            persist_path='data/docstore'
        )
        
        documents = docstore.get_all_documents()
        
        if not documents:
            print("  âš ï¸  No hi ha documents al DocStore")
            print("  ğŸ’¡ Executa primer el MÃ²dul 1 per processar PDFs")
            
            # Crear documents dummy
            print("\n  ğŸ“ Creant documents de prova...")
            documents = [
                Document(
                    text="PolÃ­tica de vacances: 30 dies anuals",
                    metadata={'filename': 'vacances.txt', 'department': 'HR'}
                ),
                Document(
                    text="Procediment de contractaciÃ³ de personal",
                    metadata={'filename': 'contractacio.txt', 'department': 'HR'}
                )
            ]
        
        print(f"  âœ“ Documents carregats: {len(documents)}")
        
        # Pipeline simplificat
        print(f"\nğŸ”„ Executant pipeline complet...")
        print(f"  ğŸ’¡ AixÃ² pot trigar uns minuts la primera vegada...")
        
        try:
            builder, index, stats = build_complete_pipeline(
                documents=documents[:2],  # NomÃ©s 2 per rapidesa
                chunking_strategy='sentence',
                embedding_model='bge-small',  # MÃ©s rÃ pid que bge-m3
                vector_store_backend='chroma'
            )
            
            print(f"\nâœ… Pipeline completat!")
            print(f"\nğŸ“Š EstadÃ­stiques:")
            print(f"  - Documents processats: {stats['documents']}")
            print(f"  - Chunks generats: {stats['nodes']}")
            print(f"  - Model embeddings: {stats['embedding']['name']}")
            print(f"  - Dimensions: {stats['embedding']['dimensions']}")
            print(f"  - Vector store: {stats['vector_store']['backend']}")
            
            # Provar query
            print(f"\nğŸ” Provant consulta...")
            query_engine = builder.get_query_engine(similarity_top_k=3)
            
            response = query_engine.query("Quants dies de vacances tenim?")
            
            print(f"  âœ“ Resposta: {response}")
            
        except Exception as e:
            print(f"  âŒ Error en pipeline: {e}")
            print(f"  ğŸ’¡ Verifica que tens instalÂ·lats: chromadb, sentence-transformers")
        
    except Exception as e:
        print(f"  âŒ Error carregant DocStore: {e}")


def example_6_hybrid_search():
    """
    Exemple 6: Cerca hÃ­brida (vectorial + metadata)
    """
    print("\n" + "="*70)
    print("EXEMPLE 6: HYBRID SEARCH")
    print("="*70)
    
    from llama_index.core.schema import TextNode
    import random
    
    # Crear nodes amb embeddings i metadata
    nodes = []
    departments = ['IT', 'Legal', 'HR', 'Finance']
    languages = ['ca', 'es', 'en']
    
    for i in range(10):
        node = TextNode(
            text=f"Document {i} amb contingut important",
            metadata={
                'department': departments[i % len(departments)],
                'language': languages[i % len(languages)],
                'priority': random.choice(['high', 'medium', 'low'])
            }
        )
        node.embedding = [random.random() for _ in range(384)]
        nodes.append(node)
    
    print(f"\nğŸ“‹ Creats {len(nodes)} nodes amb metadata")
    
    # Crear metadata index
    metadata_index = MetadataIndex()
    metadata_index.index_nodes(nodes)
    
    print(f"  âœ“ Metadata indexada")
    
    # Simular resultats vectorials
    vector_node_ids = [n.node_id for n in nodes[:7]]  # Top 7 de vectorial
    
    print(f"\nğŸ” Cerca hÃ­brida:")
    print(f"  - Resultats vectorials: {len(vector_node_ids)}")
    
    # Aplicar filtres
    filtered = hybrid_search(
        vector_results=vector_node_ids,
        metadata_index=metadata_index,
        metadata_filters={
            'department': 'IT',
            'language': 'ca'
        }
    )
    
    print(f"  - DesprÃ©s de filtres: {len(filtered)}")
    
    # Mostrar nodes filtrats
    for node_id in filtered:
        node_meta = metadata_index.get_node_metadata(node_id)
        print(f"    âœ“ {node_id[:8]}... â†’ {node_meta}")


def main():
    """Executar tots els exemples"""
    print("\n" + "ğŸš€ " + "="*68)
    print("   EXEMPLES DEL MÃ’DUL 2: DOCUMENT PROCESSING & INDEXING")
    print("="*70 + "\n")
    
    examples = [
        ("Chunking Strategies", example_1_chunking),
        ("Embedding Generation", example_2_embeddings),
        ("Vector Store", example_3_vector_store),
        ("Metadata Index", example_4_metadata_index),
        ("Complete Pipeline", example_5_complete_pipeline),
        ("Hybrid Search", example_6_hybrid_search)
    ]
    
    for name, func in examples:
        try:
            func()
        except KeyboardInterrupt:
            print(f"\nâš ï¸  Interromput per l'usuari")
            break
        except Exception as e:
            print(f"\nâŒ Error en '{name}': {e}")
            logger.exception(f"Error en exemple {name}")
            continue
    
    print("\n" + "="*70)
    print("âœ… EXEMPLES COMPLETATS")
    print("="*70 + "\n")
    
    print("ğŸ’¡ PROPERS PASSOS:")
    print("  1. Revisa els resultats dels exemples")
    print("  2. Ajusta configuraciÃ³ al fitxer .env")
    print("  3. Executa el pipeline complet amb els teus documents")
    print("  4. Passa al MÃ²dul 3: Query & Retrieval")
    print()


if __name__ == "__main__":
    main()
